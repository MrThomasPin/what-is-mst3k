{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.preprocessing import normalize, scale, Normalizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import os, re\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "import urllib\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "# pip install git+git://github.com/mgelbart/plot-classifier.git\n",
    "from plot_classifier import plot_classifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "import altair as alt\n",
    "\n",
    "# pip install ipython-autotime\n",
    "import autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the charact...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like clichÃ©'e version of gangst...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyone liked, and although Walter Hill is no mop-top he's second to none when it comes to thought provoking action movies. The nineties came and social pla...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type  \\\n",
       "0           0  test   \n",
       "1           1  test   \n",
       "2           2  test   \n",
       "3           3  test   \n",
       "\n",
       "                                                                                                                                                                                                    review  \\\n",
       "0  Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the charact...   \n",
       "1  This is an example of why the majority of action films are the same. Generic and boring, there's really nothing worth watching here. A complete waste of the then barely-tapped talents of Ice-T and...   \n",
       "2  First of all I hate those moronic rappers, who could'nt act if they had a gun pressed against their foreheads. All they do is curse and shoot each other and acting like clichÃ©'e version of gangst...   \n",
       "3  Not even the Beatles could write songs everyone liked, and although Walter Hill is no mop-top he's second to none when it comes to thought provoking action movies. The nineties came and social pla...   \n",
       "\n",
       "  label         file  \n",
       "0   neg      0_2.txt  \n",
       "1   neg  10000_4.txt  \n",
       "2   neg  10001_1.txt  \n",
       "3   neg  10002_3.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read IMDB movie reviews into a pandas DataFrame\n",
    "imdb_df = pd.read_csv('data/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "# Only keep the reviews with pos and neg labels\n",
    "imdb_df = imdb_df[imdb_df['label'].str.startswith(('pos','neg'))]\n",
    "imdb_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(imdb_df['review'], \n",
    "                                                                        imdb_df['label'], \n",
    "                                                                        test_size = 0.20, \n",
    "                                                                        random_state = 12)\n",
    "vec = CountVectorizer(max_features=5000,                       \n",
    "                      stop_words='english')\n",
    "\n",
    "X_train_counts = vec.fit_transform(X_train) \n",
    "  \n",
    "X_test_counts = vec.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vec.get_feature_names()\n",
    "weights = lr.coef_.flatten()\n",
    "\n",
    "inds = np.argsort(lr.coef_.flatten())\n",
    "\n",
    "negative_words = [vocab[index] for index in inds[:10]]\n",
    "\n",
    "neg_words_weights = [(weights[index]) for index in inds[:10]]\n",
    "\n",
    "results = pd.DataFrame({'Neg Words':negative_words, 'Weights':neg_words_weights})\n",
    "\n",
    "results.to_csv(r'table\\negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neg Words</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waste</td>\n",
       "      <td>-2.250113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disappointment</td>\n",
       "      <td>-2.175797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mst3k</td>\n",
       "      <td>-2.171390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mildly</td>\n",
       "      <td>-1.952146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>forgettable</td>\n",
       "      <td>-1.908331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>laughable</td>\n",
       "      <td>-1.896478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>uninspired</td>\n",
       "      <td>-1.881927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lousy</td>\n",
       "      <td>-1.820625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>redeeming</td>\n",
       "      <td>-1.773734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.749149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Neg Words   Weights\n",
       "0           waste -2.250113\n",
       "1  disappointment -2.175797\n",
       "2           mst3k -2.171390\n",
       "3          mildly -1.952146\n",
       "4     forgettable -1.908331\n",
       "5       laughable -1.896478\n",
       "6      uninspired -1.881927\n",
       "7           lousy -1.820625\n",
       "8       redeeming -1.773734\n",
       "9           worst -1.749149"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
